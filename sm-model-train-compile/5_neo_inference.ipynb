{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65cf386b",
   "metadata": {},
   "source": [
    "# Module 5. (Optional) Check DLR inference results in the cloud\n",
    "---\n",
    "\n",
    "\n",
    "**[Caution] In order to run this module successfully, the instance type of the SageMaker notebook instance must be `ml.m4.xlarge`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%store -r\n",
    "\n",
    "try:\n",
    "    model_cloud_cpu_s3_path\n",
    "    print(\"[OK] You can proceed.\")\n",
    "except NameError:\n",
    "    print(\"+\"*60)\n",
    "    print(\"[ERROR] Please run previous notebooks and before you continue.\")\n",
    "    print(\"+\"*60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlr==1.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a76bf03",
   "metadata": {},
   "source": [
    "### Extract Model Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf252f",
   "metadata": {},
   "source": [
    "If you continue to do hands-on deploying Greengrass ML component in the Cloud9 environment, please take note of the output of the last part of `4.1_neo_compile.ipynb`. You must run the shell command below on Cloud9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {model_cloud_cpu_s3_path}\n",
    "\n",
    "cd /home/ec2-user/SageMaker/aiot-e2e-sagemaker-greengrass-v2-nvidia-jetson/sm-model-train-compile\n",
    "rm -rf model_cpu\n",
    "mkdir model_cpu && cd model_cpu\n",
    "aws s3 cp $1 . --recursive\n",
    "tar -xzvf model-ml_m4.tar.gz && rm model-ml_m4.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83392672",
   "metadata": {},
   "source": [
    "### Prediction Test\n",
    "The code below is the same code as `ggv2-deploy-on-device/artifacts/test_dlr.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a00d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import dlr\n",
    "from dlr import DLRModel\n",
    "\n",
    "\n",
    "def load_classes_dict(filename='classes_dict.json'):\n",
    "    with open(filename, 'r') as fp:\n",
    "        classes_dict = json.load(fp)\n",
    "\n",
    "    classes_dict = {int(k):v for k,v in classes_dict.items()}        \n",
    "    return classes_dict\n",
    "    \n",
    "\n",
    "def load_image(image_path):\n",
    "    image_data = cv2.imread(image_path)\n",
    "    image_data = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "    return image_data\n",
    "\n",
    "\n",
    "def preprocess_image(image, image_shape=(224,224)):\n",
    "    cvimage = cv2.resize(image, image_shape)\n",
    "    img = np.asarray(cvimage, dtype='float32')\n",
    "    img /= 255.0 # scale 0 to 1\n",
    "    mean = np.array([0.485, 0.456, 0.406]) \n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = (img - mean) / std\n",
    "    img = np.transpose(img, (2,0,1)) \n",
    "    img = np.expand_dims(img, axis=0) # e.g., [1x3x224x224]\n",
    "    return img\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    x_exp = np.exp(x - np.max(x))\n",
    "    f_x = x_exp / np.sum(x_exp)\n",
    "    return f_x\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "model = DLRModel(f'model_{device}', device)\n",
    "sample_image_dir = 'sample_images'\n",
    "classes_dict = load_classes_dict('classes_dict.json')\n",
    "\n",
    "extensions = (f\"{sample_image_dir}/*.jpg\", f\"{sample_image_dir}/*.jpeg\")\n",
    "img_filelist = [f for f_ in [glob.glob(e) for e in extensions] for f in f_]\n",
    "print(img_filelist)\n",
    "\n",
    "for img_filepath in img_filelist[:-1]:\n",
    "    ground_truth = img_filepath.split('/')[-1]\n",
    "    img = load_image(img_filepath)\n",
    "    img_data = preprocess_image(img)\n",
    "    \n",
    "    output = model.run(img_data)  \n",
    "    probs = softmax(output[0][0])\n",
    "    sort_classes_by_probs = np.argsort(probs)[::-1]\n",
    "\n",
    "    idx = sort_classes_by_probs[0]\n",
    "    print(\"+\"*80)\n",
    "    print(f'predicted = {classes_dict[idx]}, {probs[idx]*100:.2f}%')\n",
    "    print(f'ground_truth = {ground_truth}')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p37",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
